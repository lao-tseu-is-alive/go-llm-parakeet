services:
  # docker compose up --build 

  download-local-llm:
    image: curlimages/curl:8.12.1
    #profiles: ["disabled"]
    entrypoint:
      - "sh"
      - "-c"
      - 'curl -s "${MODEL_RUNNER_BASE_URL}/models/create" -d "{\"from\": \"${LLM_CHAT}\"}"'

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - MODEL_RUNNER_BASE_URL=${MODEL_RUNNER_BASE_URL}
      - LLM_CHAT=${LLM_CHAT}
    depends_on:
      download-local-llm:
        condition: service_completed_successfully
    develop:
      watch:
        - action: rebuild
          path: ./backend/main.go


  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - 9090:8501
    environment:
      - BACKEND_SERVICE_URL=http://backend:5050
      - PAGE_TITLE=ðŸ™‚ðŸ¤“ðŸ¥¸ We are Bob!
      - PAGE_HEADER=We are legion ðŸ¤–ðŸ¤–ðŸ¤–
      - PAGE_ICON=ðŸ¤–
    depends_on:
      - backend
    develop:
      watch:
        - action: rebuild
          path: ./frontend/app.py


