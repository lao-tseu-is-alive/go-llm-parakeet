package squawk

import (
	"github.com/parakeet-nest/parakeet/completion"
	"github.com/parakeet-nest/parakeet/llm"
)

// chatExec executes a chat completion request and returns the model's response.
// This is an internal method used by Chat and other higher-level methods.
//
// The method performs the following steps:
// 1. Constructs a query with the current model, messages, and options
// 2. Calls the completion.Chat function with the configured provider
// 3. Updates the lastAnswer field with the response
// 4. Returns the answer and any error that occurred
//
// Returns:
//   - llm.Answer: The model's response containing the generated message
//   - error: Any error that occurred during the completion request
//
// Example usage (internal):
//   answer, err := squawk.chatExec()
//   if err != nil {
//       return err
//   }
func (s *Squawk) chatExec() (llm.Answer, error) {
	query := llm.Query{
		Model:    s.chatModel,
		Messages: s.setOfMessages,
		Options:  s.options,
	}
	// Call the chat function with the provided model and options
	answer, err := completion.Chat(s.apiUrl, query, s.provider, s.openAPIKey)
	if err != nil {
		return llm.Answer{}, err
	}
	s.lastAnswer = answer
	return answer, nil
}


// chatStreamExec executes a streaming chat completion request and handles the response
// through a callback function. This is an internal method used by ChatStream.
//
// The method performs the following steps:
// 1. Constructs a query with the current model, messages, and options
// 2. Calls the completion.ChatStream function with the configured provider
// 3. Updates the lastAnswer field with the final response
// 4. Returns the final answer and any error that occurred
//
// Parameters:
//   - callBack: A function that receives each streaming response (llm.Answer)
//     and returns an error if processing should stop
//
// Returns:
//   - llm.Answer: The final complete response from the model
//   - error: Any error that occurred during the streaming request
//
// Example usage through ChatStream:
//
//	squawk := New().
//	  Model("mistral:latest").
//	  Provider(provider.Ollama).
//	  System("You are a Go expert").
//	  User("Explain concurrency patterns").
//	  ChatStream(func(answer llm.Answer, self *Squawk) error {
//	      fmt.Print(answer.Message.Content)
//	      return nil
//	  })
func (s *Squawk) chatStreamExec(callBack func(answer llm.Answer) error) (llm.Answer, error) {
	query := llm.Query{
		Model:    s.chatModel,
		Messages: s.setOfMessages,
		Options:  s.options,
	}
	answer, err := completion.ChatStream(s.apiUrl, query, callBack, s.provider, s.openAPIKey)
	if err != nil {
		return llm.Answer{}, err
	}
	s.lastAnswer = answer
	return answer, nil

}

// Chat executes a non-streaming chat completion request and handles the response
// through a callback function.
//
// Parameters:
//   - callBack: A function that receives:
//   - answer: The llm.Answer containing the model's response
//   - self: A pointer to the current Squawk instance
//   - err: Any error that occurred during the request
//
// Returns:
//   - *Squawk: A pointer to the same Squawk instance for method chaining
//
// Example with Ollama provider:
//
//	squawk := New().
//	  Model("mistral:latest").
//	  Provider(provider.Ollama).
//	  System("You are a Go expert").
//	  User("What is a channel?").
//	  Chat(func(answer llm.Answer, self *Squawk, err error) {
//	      if err != nil {
//	          fmt.Printf("Error: %v\n", err)
//	          return
//	      }
//	      fmt.Println(answer.Message.Content)
//	  })
//
// Error Handling:
//   - If an error occurs, the callback is invoked with the error
//   - The error is stored in lastError field
//   - The method continues to support method chaining
//
// Common use cases:
//   - Getting single responses from the model
//   - Question answering
//   - Code generation
//   - Text analysis tasks
func (s *Squawk) Chat(callBack func(answer llm.Answer, self *Squawk, err error)) *Squawk {
	answer, err := s.chatExec()
	if err != nil {
		callBack(answer, s, err)
		s.lastError = err
		return s
	}
	callBack(answer, s, nil)
	//s.lastAnswer = answer
	return s
}

// ChatStream executes a streaming chat completion request and handles the response
// through a callback function. This method provides real-time responses as they
// are generated by the model.
//
// Parameters:
//   - callBack: A function that receives:
//   - answer: The llm.Answer containing each chunk of the streaming response
//   - self: A pointer to the current Squawk instance
//     Returns an error if processing should stop
//
// Returns:
//   - *Squawk: A pointer to the same Squawk instance for method chaining
//
// Error Handling:
//   - If an error occurs, lastAnswer is reset to empty and lastError is set
//   - Successful completion updates lastAnswer with the final response
//   - lastError is set to nil on success
//
// Example with Ollama provider:
//
//	squawk := New().
//	  Model("mistral:latest").
//	  Provider(provider.Ollama).
//	  System("You are a Go expert").
//	  User("Explain channels in detail").
//	  ChatStream(func(answer llm.Answer, self *Squawk) error {
//	      if answer.Error != nil {
//	          fmt.Printf("Stream error: %v\n", answer.Error)
//	          return answer.Error
//	      }
//
//	      fmt.Print(answer.Message.Content)
//	      return nil
//	  })
func (s *Squawk) ChatStream(callBack func(answer llm.Answer, self *Squawk) error) *Squawk {
	answer, err := s.chatStreamExec(func(answer llm.Answer) error {
		return callBack(answer, s)
	})
	if err != nil {
		s.lastAnswer = llm.Answer{}
		s.lastError = err
		return s
	}
	s.lastAnswer = answer
	s.lastError = nil
	return s
}
